{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../data/train/53717_sat.jpg', '../../data/train/12320_sat.jpg', '../../data/train/53640_sat.jpg', '../../data/train/12480_sat.jpg', '../../data/train/27456_sat.jpg', '../../data/train/40397_sat.jpg', '../../data/train/34417_sat.jpg', '../../data/train/24192_sat.jpg', '../../data/train/42547_sat.jpg', '../../data/train/18984_sat.jpg']\n",
      "['../../data/train/52857_msk.png', '../../data/train/5009_msk.png', '../../data/train/29412_msk.png', '../../data/train/50596_msk.png', '../../data/train/8066_msk.png', '../../data/train/11225_msk.png', '../../data/train/43068_msk.png', '../../data/train/48526_msk.png', '../../data/train/47933_msk.png', '../../data/train/15692_msk.png']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "path_to_train = '../../data/train'\n",
    "glob_train_imgs = os.path.join(path_to_train, '*_sat.jpg')\n",
    "glob_train_masks = os.path.join(path_to_train, '*_msk.png')\n",
    "\n",
    "train_img_paths = glob(glob_train_imgs)\n",
    "train_mask_paths = glob(glob_train_masks)\n",
    "print(train_img_paths[:10])\n",
    "print(train_mask_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "def get_img_id(img_path):\n",
    "  img_basename = os.path.basename(img_path)\n",
    "  img_id = os.path.splitext(img_basename)[0][:-len('_sat')]\n",
    "  return img_id\n",
    "\n",
    "def img_gen(img_paths, img_size=(512, 512)):\n",
    "  #Iterate over all image paths\n",
    "  for img_path in img_paths:\n",
    "    img_id = get_img_id(img_path)\n",
    "    mask_path = os.path.join(path_to_train,img_id+'_msk.png')\n",
    "    \n",
    "    img = imread(img_path)/255\n",
    "    mask = rgb2gray(imread(mask_path))\n",
    "    \n",
    "#     img = resize(img, img_size, preserve_range = True)\n",
    "#     mask = resize(mask, img_size, mode='constant', preserve_range = True)\n",
    "    \n",
    "    mask = (mask>=0.5).astype(float)\n",
    "    mask = np.reshape(mask, (512,512,1))\n",
    "    yield img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_non_outlier_data(train_img_paths):\n",
    "  train_path_without_outlier = []\n",
    "  for index,image_path in enumerate(train_img_paths):\n",
    "    if index % 500 == 0:\n",
    "      print(index)\n",
    "    img_id = get_img_id(image_path)\n",
    "    mask_path = os.path.join('../../data/train',img_id+'_msk.png')\n",
    "    mask = rgb2gray(imread(mask_path))\n",
    "    if len(np.where(mask.flatten() != 0)[0]) != 0:\n",
    "      train_path_without_outlier.append(image_path)\n",
    "  return train_path_without_outlier\n",
    "\n",
    "\n",
    "train_img_paths = get_non_outlier_data(train_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Keras takes its input in batches \n",
    "# (i.e. a batch size of 32 would correspond to 32 images and 32 masks from the generator)\n",
    "# The generator should run forever\n",
    "def image_batch_generator(img_paths, batchsize=32):\n",
    "    while True:\n",
    "        ig = img_gen(img_paths)\n",
    "        batch_img, batch_mask = [], []\n",
    "        \n",
    "        for img, mask in ig:\n",
    "            # Add the image and mask to the batch\n",
    "            batch_img.append(img)\n",
    "            batch_mask.append(mask)\n",
    "            # If we've reached our batchsize, yield the batch and reset\n",
    "            if len(batch_img) == batchsize:\n",
    "                yield np.stack(batch_img, axis=0), np.stack(batch_mask, axis=0)\n",
    "                batch_img, batch_mask = [], []\n",
    "        \n",
    "        # If we have an nonempty batch left, yield it out and reset\n",
    "        if len(batch_img) != 0:\n",
    "            yield np.stack(batch_img, axis=0), np.stack(batch_mask, axis=0)\n",
    "            batch_img, batch_mask = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7667\n",
      "667\n",
      "(4, 512, 512, 3)\n",
      "train steps 1917\n",
      "val steps 167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCHSIZE = 4\n",
    "\n",
    "# Split the data into a train and validation set\n",
    "train_img_paths, val_img_paths = train_test_split(train_img_paths, test_size=0.08)\n",
    "print(len(train_img_paths))\n",
    "print(len(val_img_paths))\n",
    "\n",
    "# Create the train and validation generators\n",
    "traingen = image_batch_generator(train_img_paths, batchsize=BATCHSIZE)\n",
    "valgen = image_batch_generator(val_img_paths, batchsize=BATCHSIZE)\n",
    "print(next(traingen)[0].shape)\n",
    "def calc_steps(data_len, batchsize):\n",
    "    return (data_len + batchsize - 1) // batchsize\n",
    "\n",
    "# Calculate the steps per epoch\n",
    "train_steps = calc_steps(len(train_img_paths), BATCHSIZE)\n",
    "val_steps = calc_steps(len(val_img_paths), BATCHSIZE)\n",
    "print(\"train steps {}\".format(train_steps))\n",
    "print(\"val steps {}\".format(val_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (from seaborn) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (from seaborn) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (from seaborn) (1.2.1)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (from seaborn) (0.24.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.3.1)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn) (2018.9)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (40.8.0)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/unet/lib/python3.6/site-packages (from cycler>=0.10->matplotlib>=1.4.3->seaborn) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
    "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 512, 512, 64) 1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 512, 512, 64) 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 512, 512, 64) 36928       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 512, 512, 64) 256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 256, 256, 64) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 256, 256, 128 73856       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256, 256, 128 512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 256, 256, 128 147584      batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 256, 256, 128 512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 128, 128, 128 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 128, 128, 256 295168      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128, 128, 256 1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 128, 128, 256 590080      batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 128, 128, 256 1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 64, 64, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 512)  1180160     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64, 64, 512)  2048        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 512)  2359808     batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 64, 64, 512)  2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 512)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 1024) 4719616     max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 1024) 4096        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 1024) 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 1024) 9438208     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 1024) 4096        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 1024) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 512)  2097664     up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 1024) 0           batch_normalization_26[0][0]     \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 64, 512)  2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 64, 64, 512)  2359808     batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 64, 512)  2048        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 512 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 128, 256 524544      up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128, 128, 512 0           batch_normalization_24[0][0]     \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 128, 128, 256 1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 128, 128, 256 590080      batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 128, 128, 256 1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 256 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 256, 256, 128 131200      up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 256, 256, 256 0           batch_normalization_22[0][0]     \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 256, 256, 128 295040      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 256, 256, 128 512         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 256, 256, 128 147584      batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 256, 256, 128 512         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 512, 512, 128 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 512, 512, 64) 32832       up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 512, 512, 128 0           batch_normalization_20[0][0]     \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 512, 512, 64) 256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 512, 512, 64) 36928       batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 512, 512, 64) 256         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 512, 512, 1)  65          batch_normalization_36[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 31,055,297\n",
      "Trainable params: 31,043,521\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "(https://arxiv.org/abs/1505.04597)\n",
    "---\n",
    "img_shape: (height, width, channels)\n",
    "out_ch: number of output channels\n",
    "start_ch: number of channels of the first conv\n",
    "depth: zero indexed depth of the U-structure\n",
    "inc_rate: rate at which the conv channels will increase\n",
    "activation: activation function after convolutions\n",
    "dropout: amount of dropout in the contracting part\n",
    "batchnorm: adds Batch Normalization if true\n",
    "maxpool: use strided conv instead of maxpooling if false\n",
    "upconv: use transposed conv instead of upsamping + conv if false\n",
    "residual: add residual connections around each conv block if true\n",
    "'''\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "def conv_block(m, dim, acti, bn, res, do=0):\n",
    "\tn = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
    "\tn = BatchNormalization()(n) if bn else n\n",
    "\tn = Dropout(do)(n) if do else n\n",
    "\tn = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
    "\tn = BatchNormalization()(n) if bn else n\n",
    "\treturn Concatenate()([m, n]) if res else n\n",
    "\n",
    "def level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
    "\tif depth > 0:\n",
    "\t\tn = conv_block(m, dim, acti, bn, res)\n",
    "\t\tm = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
    "\t\tm = level_block(m, int(inc*dim), depth-1, inc, acti, do, bn, mp, up, res)\n",
    "\t\tif up:\n",
    "\t\t\tm = UpSampling2D()(m)\n",
    "\t\t\tm = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
    "\t\telse:\n",
    "\t\t\tm = Conv2DTranspose(dim, 3, strides=2, activation=acti, padding='same')(m)\n",
    "\t\tn = Concatenate()([n, m])\n",
    "\t\tm = conv_block(n, dim, acti, bn, res)\n",
    "\telse:\n",
    "\t\tm = conv_block(m, dim, acti, bn, res, do)\n",
    "\treturn m\n",
    "\n",
    "def UNet(img_shape, out_ch=1, start_ch=64, depth=4, inc_rate=2., activation='relu', \n",
    "\t\t dropout=0.5, batchnorm=True, maxpool=True, upconv=True, residual=False):\n",
    "\ti = Input(shape=img_shape)\n",
    "\to = level_block(i, start_ch, depth, inc_rate, activation, dropout, batchnorm, maxpool, upconv, residual)\n",
    "\to = Conv2D(out_ch, 1, activation='sigmoid')(o)\n",
    "\treturn Model(inputs=i, outputs=o)\n",
    "\n",
    "# This is the competition metric implemented using Keras\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * (K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "# We'll construct a Keras Loss that incorporates the DICE score\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1. - (2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.)\n",
    "\n",
    "\n",
    "smooth = 1e-9\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.45 * binary_crossentropy(y_true, y_pred) + 0.55 * dice_loss(y_true, y_pred)\n",
    "  \n",
    "def ln_dice(y_true, y_pred):\n",
    "  y_true_f = K.flatten(y_true)\n",
    "  y_pred = K.cast(y_pred, 'float32')\n",
    "  y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "  intersection = y_true_f * y_pred_f\n",
    "  score = 2. * (K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "  return K.log(score)\n",
    "\n",
    "def new_bce_dice_loss(y_true, y_pred):\n",
    "  return binary_crossentropy(y_true, y_pred) - ln_dice(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Build U-Net model\n",
    "model = UNet((512, 512, 3))\n",
    "model.compile(Adam(lr=1e-4), loss=bce_dice_loss, metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 293/1917 [===>..........................] - ETA: 1:31:50 - loss: 0.7765 - dice_coef: 0.2096"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint('id55-{epoch:02d}-{val_loss:.4f}.h5', verbose=1)\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "    traingen, \n",
    "    steps_per_epoch=train_steps, \n",
    "    epochs=50, # Change this to a larger number to train for longer\n",
    "    validation_data=valgen, \n",
    "    validation_steps=val_steps, \n",
    "    verbose=1,\n",
    "    max_queue_size=5,  # Change this number based on memory restrictions\n",
    "    callbacks = [checkpointer]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unet_1)",
   "language": "python",
   "name": "unet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
